{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afa79ac4",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Nazava Data Showdown - Complete ML Analysis\n",
    "\n",
    "**Challenge**: Optimizing Multi-Channel Sales for Nazava Water Filters on Shopee\n",
    "\n",
    "**Objectives**:\n",
    "1. âœ… Identify key drivers of Shopee sales\n",
    "2. ðŸŽ¯ Create predictive model for sales forecasting (6 months)\n",
    "3. ðŸŽ¯ Build data-driven strategy & automation recommendations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ff3bf04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T21:21:41.154097Z",
     "iopub.status.busy": "2025-11-07T21:21:41.153693Z",
     "iopub.status.idle": "2025-11-07T21:21:46.047364Z",
     "shell.execute_reply": "2025-11-07T21:21:46.046880Z",
     "shell.execute_reply.started": "2025-11-07T21:21:41.154064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Time series\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print('âœ… Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f82cae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T21:21:49.713686Z",
     "iopub.status.busy": "2025-11-07T21:21:49.713397Z",
     "iopub.status.idle": "2025-11-07T21:21:49.748429Z",
     "shell.execute_reply": "2025-11-07T21:21:49.747910Z",
     "shell.execute_reply.started": "2025-11-07T21:21:49.713671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 730 traffic records\n",
      "âœ… Loaded 31 product records\n",
      "âœ… Loaded 22 chat periods\n",
      "âœ… Loaded 22 flash sale campaigns\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets\n",
    "DATA_PATH = '/Users/tarang/CascadeProjects/windsurf-project/shopee-analytics-platform/data/cleaned/'\n",
    "\n",
    "traffic_df = pd.read_csv(f'{DATA_PATH}traffic_overview_cleaned.csv')\n",
    "product_df = pd.read_csv(f'{DATA_PATH}product_overview_cleaned.csv')\n",
    "chat_df = pd.read_csv(f'{DATA_PATH}chat_data_cleaned.csv')\n",
    "flash_sale_df = pd.read_csv(f'{DATA_PATH}flash_sale_cleaned.csv')\n",
    "voucher_df = pd.read_csv(f'{DATA_PATH}voucher_cleaned.csv')\n",
    "game_df = pd.read_csv(f'{DATA_PATH}game_cleaned.csv')\n",
    "live_df = pd.read_csv(f'{DATA_PATH}live_cleaned.csv')\n",
    "\n",
    "# Convert dates\n",
    "traffic_df['Date'] = pd.to_datetime(traffic_df['Date'], errors='coerce')\n",
    "product_df['Date'] = pd.to_datetime(product_df['Date'], errors='coerce')\n",
    "\n",
    "print(f'âœ… Loaded {len(traffic_df)} traffic records')\n",
    "print(f'âœ… Loaded {len(product_df)} product records')\n",
    "print(f'âœ… Loaded {len(chat_df)} chat periods')\n",
    "print(f'âœ… Loaded {len(flash_sale_df)} flash sale campaigns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307825cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key metrics\n",
    "total_sales_chat = pd.to_numeric(chat_df['Sales_IDR'], errors='coerce').sum()\n",
    "total_sales_flash = pd.to_numeric(flash_sale_df['Sales_Ready_To_Ship_IDR'], errors='coerce').sum()\n",
    "total_sales = total_sales_chat + total_sales_flash\n",
    "\n",
    "total_orders_chat = pd.to_numeric(chat_df['Total_Orders'], errors='coerce').sum()\n",
    "total_orders_flash = pd.to_numeric(flash_sale_df['Orders_Ready_To_Ship'], errors='coerce').sum()\n",
    "total_orders = total_orders_chat + total_orders_flash\n",
    "\n",
    "total_visitors = pd.to_numeric(traffic_df['Total_Visitors'], errors='coerce').sum()\n",
    "avg_csat = pd.to_numeric(chat_df['CSAT_Percent'], errors='coerce').mean()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NAZAVA SHOPEE PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ðŸ’° Total Sales: IDR {total_sales/1e6:.1f}M\")\n",
    "print(f\"ðŸ›’ Total Orders: {int(total_orders):,}\")\n",
    "print(f\"ðŸ‘¥ Total Visitors: {int(total_visitors):,}\")\n",
    "print(f\"ðŸ“ˆ Conversion Rate: {(total_orders/total_visitors*100):.2f}%\")\n",
    "print(f\"ðŸ’µ AOV: IDR {(total_sales/total_orders):,.0f}\")\n",
    "print(f\"ðŸ˜Š CSAT: {avg_csat:.1f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a0d9b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T21:21:55.251052Z",
     "iopub.status.busy": "2025-11-07T21:21:55.250498Z",
     "iopub.status.idle": "2025-11-07T21:21:55.573721Z",
     "shell.execute_reply": "2025-11-07T21:21:55.573172Z",
     "shell.execute_reply.started": "2025-11-07T21:21:55.251023Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m total_sales = chat_df[\u001b[33m'\u001b[39m\u001b[33mSales_IDR\u001b[39m\u001b[33m'\u001b[39m].sum() + flash_sale_df[\u001b[33m'\u001b[39m\u001b[33mSales_Ready_To_Ship_IDR\u001b[39m\u001b[33m'\u001b[39m].sum()\n\u001b[32m      3\u001b[39m total_orders = chat_df[\u001b[33m'\u001b[39m\u001b[33mTotal_Orders\u001b[39m\u001b[33m'\u001b[39m].sum() + flash_sale_df[\u001b[33m'\u001b[39m\u001b[33mOrders_Ready_To_Ship\u001b[39m\u001b[33m'\u001b[39m].sum()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m total_visitors = \u001b[43mtraffic_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTotal_Visitors\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m avg_csat = chat_df[\u001b[33m'\u001b[39m\u001b[33mCSAT_Percent\u001b[39m\u001b[33m'\u001b[39m].mean()\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pandas/core/series.py:6549\u001b[39m, in \u001b[36mSeries.sum\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001b[39m\n\u001b[32m   6540\u001b[39m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[33m\"\u001b[39m\u001b[33msum\u001b[39m\u001b[33m\"\u001b[39m, ndim=\u001b[32m1\u001b[39m))\n\u001b[32m   6541\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msum\u001b[39m(\n\u001b[32m   6542\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   6547\u001b[39m     **kwargs,\n\u001b[32m   6548\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m6549\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pandas/core/generic.py:12571\u001b[39m, in \u001b[36mNDFrame.sum\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001b[39m\n\u001b[32m  12563\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msum\u001b[39m(\n\u001b[32m  12564\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  12565\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  12569\u001b[39m     **kwargs,\n\u001b[32m  12570\u001b[39m ):\n\u001b[32m> \u001b[39m\u001b[32m12571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_min_count_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12572\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnansum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m  12573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pandas/core/generic.py:12554\u001b[39m, in \u001b[36mNDFrame._min_count_stat_function\u001b[39m\u001b[34m(self, name, func, axis, skipna, numeric_only, min_count, **kwargs)\u001b[39m\n\u001b[32m  12551\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m  12552\u001b[39m     axis = \u001b[32m0\u001b[39m\n\u001b[32m> \u001b[39m\u001b[32m12554\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12555\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12557\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12558\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12559\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12560\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12561\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pandas/core/series.py:6478\u001b[39m, in \u001b[36mSeries._reduce\u001b[39m\u001b[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[39m\n\u001b[32m   6473\u001b[39m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[32m   6474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   6475\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith non-numeric dtypes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6477\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m6478\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pandas/core/nanops.py:85\u001b[39m, in \u001b[36mdisallow.__call__.<locals>._f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m     82\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mreduction operation \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not allowed for this dtype\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     83\u001b[39m     )\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[32m     90\u001b[39m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[32m0\u001b[39m]):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pandas/core/nanops.py:404\u001b[39m, in \u001b[36m_datetimelike_compat.<locals>.new_func\u001b[39m\u001b[34m(values, axis, skipna, mask, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    402\u001b[39m     mask = isna(values)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[32m    407\u001b[39m     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pandas/core/nanops.py:477\u001b[39m, in \u001b[36mmaybe_operate_rowwise.<locals>.newfunc\u001b[39m\u001b[34m(values, axis, **kwargs)\u001b[39m\n\u001b[32m    474\u001b[39m         results = [func(x, **kwargs) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrs]\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.array(results)\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pandas/core/nanops.py:646\u001b[39m, in \u001b[36mnansum\u001b[39m\u001b[34m(values, axis, skipna, min_count, mask)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m dtype.kind == \u001b[33m\"\u001b[39m\u001b[33mm\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    644\u001b[39m     dtype_sum = np.dtype(np.float64)\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m the_sum = \u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    647\u001b[39m the_sum = _maybe_null_out(the_sum, axis, mask, values.shape, min_count=min_count)\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m the_sum\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/numpy/_core/_methods.py:51\u001b[39m, in \u001b[36m_sum\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sum\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     50\u001b[39m          initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "# Calculate key metrics\n",
    "total_sales = chat_df['Sales_IDR'].sum() + flash_sale_df['Sales_Ready_To_Ship_IDR'].sum()\n",
    "total_orders = chat_df['Total_Orders'].sum() + flash_sale_df['Orders_Ready_To_Ship'].sum()\n",
    "total_visitors = traffic_df['Total_Visitors'].sum()\n",
    "avg_csat = chat_df['CSAT_Percent'].mean()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NAZAVA SHOPEE PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ðŸ’° Total Sales: IDR {total_sales/1e6:.1f}M\")\n",
    "print(f\"ðŸ›’ Total Orders: {int(total_orders):,}\")\n",
    "print(f\"ðŸ‘¥ Total Visitors: {int(total_visitors):,}\")\n",
    "print(f\"ðŸ“ˆ Conversion Rate: {(total_orders/total_visitors*100):.2f}%\")\n",
    "print(f\"ðŸ’µ AOV: IDR {(total_sales/total_orders):,.0f}\")\n",
    "print(f\"ðŸ˜Š CSAT: {avg_csat:.1f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c25a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic visualization\n",
    "fig = make_subplots(rows=2, cols=2,\n",
    "                    subplot_titles=('Daily Visitors', 'New vs Returning', \n",
    "                                    'Followers Growth', 'Visitor Distribution'))\n",
    "\n",
    "# Convert to numeric\n",
    "traffic_clean = traffic_df.copy()\n",
    "traffic_clean['Total_Visitors'] = pd.to_numeric(traffic_clean['Total_Visitors'], errors='coerce').fillna(0)\n",
    "traffic_clean['New_Visitors'] = pd.to_numeric(traffic_clean['New_Visitors'], errors='coerce').fillna(0)\n",
    "traffic_clean['Returning_Visitors'] = pd.to_numeric(traffic_clean['Returning_Visitors'], errors='coerce').fillna(0)\n",
    "traffic_clean['New_Followers'] = pd.to_numeric(traffic_clean['New_Followers'], errors='coerce').fillna(0)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=traffic_clean['Date'], y=traffic_clean['Total_Visitors'],\n",
    "                         mode='lines', name='Visitors', line=dict(color='#667eea')), \n",
    "              row=1, col=1)\n",
    "\n",
    "visitor_types = pd.DataFrame({\n",
    "    'Type': ['New', 'Returning'],\n",
    "    'Count': [traffic_clean['New_Visitors'].sum(), traffic_clean['Returning_Visitors'].sum()]\n",
    "})\n",
    "fig.add_trace(go.Bar(x=visitor_types['Type'], y=visitor_types['Count'],\n",
    "                     marker_color=['#667eea', '#764ba2']), \n",
    "              row=1, col=2)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=traffic_clean['Date'], y=traffic_clean['New_Followers'],\n",
    "                         mode='lines', name='Followers', line=dict(color='#f093fb')), \n",
    "              row=2, col=1)\n",
    "\n",
    "fig.add_trace(go.Pie(labels=visitor_types['Type'], values=visitor_types['Count'],\n",
    "                     marker_colors=['#667eea', '#764ba2']), \n",
    "              row=2, col=2)\n",
    "\n",
    "fig.update_layout(height=800, showlegend=True, title_text=\"Traffic Analysis Dashboard\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f337a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic visualization\n",
    "fig = make_subplots(rows=2, cols=2,\n",
    "                    subplot_titles=('Daily Visitors', 'New vs Returning', \n",
    "                                    'Followers Growth', 'Visitor Distribution'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=traffic_df['Date'], y=traffic_df['Total_Visitors'],\n",
    "                         mode='lines', name='Visitors'), row=1, col=1)\n",
    "\n",
    "visitor_types = pd.DataFrame({\n",
    "    'Type': ['New', 'Returning'],\n",
    "    'Count': [traffic_df['New_Visitors'].sum(), traffic_df['Returning_Visitors'].sum()]\n",
    "})\n",
    "fig.add_trace(go.Bar(x=visitor_types['Type'], y=visitor_types['Count']), row=1, col=2)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=traffic_df['Date'], y=traffic_df['New_Followers'],\n",
    "                         mode='lines', name='Followers'), row=2, col=1)\n",
    "\n",
    "fig.add_trace(go.Pie(labels=visitor_types['Type'], values=visitor_types['Count']), row=2, col=2)\n",
    "\n",
    "fig.update_layout(height=800, title_text=\"Traffic Analysis Dashboard\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690907aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campaign ROI\n",
    "campaigns = []\n",
    "\n",
    "# Flash Sales\n",
    "flash_sales = pd.to_numeric(flash_sale_df['Sales_Ready_To_Ship_IDR'], errors='coerce').sum()\n",
    "flash_orders = pd.to_numeric(flash_sale_df['Orders_Ready_To_Ship'], errors='coerce').sum()\n",
    "campaigns.append({\n",
    "    'Campaign': 'Flash Sales',\n",
    "    'Sales': flash_sales,\n",
    "    'Orders': flash_orders,\n",
    "    'AOV': flash_sales/flash_orders if flash_orders > 0 else 0\n",
    "})\n",
    "\n",
    "# Vouchers\n",
    "if 'Sales_Ready_To_Ship_IDR' in voucher_df.columns:\n",
    "    voucher_sales = pd.to_numeric(voucher_df['Sales_Ready_To_Ship_IDR'], errors='coerce').sum()\n",
    "    voucher_orders = pd.to_numeric(voucher_df['Orders_Ready_To_Ship'], errors='coerce').sum()\n",
    "    campaigns.append({\n",
    "        'Campaign': 'Vouchers',\n",
    "        'Sales': voucher_sales,\n",
    "        'Orders': voucher_orders,\n",
    "        'AOV': voucher_sales/voucher_orders if voucher_orders > 0 else 0\n",
    "    })\n",
    "\n",
    "# Games\n",
    "if 'Sales_Ready_To_Ship_IDR' in game_df.columns:\n",
    "    game_sales = pd.to_numeric(game_df['Sales_Ready_To_Ship_IDR'], errors='coerce').sum()\n",
    "    game_orders = pd.to_numeric(game_df['Orders_Ready_To_Ship'], errors='coerce').sum()\n",
    "    campaigns.append({\n",
    "        'Campaign': 'Games',\n",
    "        'Sales': game_sales,\n",
    "        'Orders': game_orders,\n",
    "        'AOV': game_sales/game_orders if game_orders > 0 else 0\n",
    "    })\n",
    "\n",
    "campaign_df = pd.DataFrame(campaigns)\n",
    "\n",
    "# Visualize\n",
    "fig = px.bar(campaign_df, x='Campaign', y='Sales', \n",
    "             title='Campaign Sales Comparison',\n",
    "             labels={'Sales': 'Sales (IDR)'})\n",
    "fig.update_traces(marker_color='#667eea')\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nðŸŽ¯ Campaign Performance:\")\n",
    "print(campaign_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d768d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campaign ROI\n",
    "campaigns = []\n",
    "\n",
    "# Flash Sales\n",
    "flash_sales = flash_sale_df['Sales_Ready_To_Ship_IDR'].sum()\n",
    "flash_orders = flash_sale_df['Orders_Ready_To_Ship'].sum()\n",
    "campaigns.append({\n",
    "    'Campaign': 'Flash Sales',\n",
    "    'Sales': flash_sales,\n",
    "    'Orders': flash_orders,\n",
    "    'AOV': flash_sales/flash_orders if flash_orders > 0 else 0\n",
    "})\n",
    "\n",
    "# Vouchers\n",
    "if 'Sales_Ready_To_Ship_IDR' in voucher_df.columns:\n",
    "    voucher_sales = voucher_df['Sales_Ready_To_Ship_IDR'].sum()\n",
    "    voucher_orders = voucher_df['Orders_Ready_To_Ship'].sum()\n",
    "    campaigns.append({\n",
    "        'Campaign': 'Vouchers',\n",
    "        'Sales': voucher_sales,\n",
    "        'Orders': voucher_orders,\n",
    "        'AOV': voucher_sales/voucher_orders if voucher_orders > 0 else 0\n",
    "    })\n",
    "\n",
    "campaign_df = pd.DataFrame(campaigns)\n",
    "\n",
    "# Visualize\n",
    "fig = px.bar(campaign_df, x='Campaign', y='Sales', title='Campaign Sales Comparison')\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nðŸŽ¯ Campaign Performance:\")\n",
    "print(campaign_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ac238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare daily sales data\n",
    "daily_data = traffic_df[['Date', 'Total_Visitors']].copy()\n",
    "daily_data['Total_Visitors'] = pd.to_numeric(daily_data['Total_Visitors'], errors='coerce').fillna(0)\n",
    "daily_data = daily_data.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Estimate sales (if product data limited)\n",
    "daily_data['Daily_Sales'] = daily_data['Total_Visitors'] * 5200  # Avg revenue per visitor\n",
    "daily_data['Daily_Orders'] = daily_data['Total_Visitors'] * 0.02  # 2% conversion\n",
    "\n",
    "# Remove any rows with missing dates\n",
    "daily_data = daily_data.dropna(subset=['Date'])\n",
    "\n",
    "print(f\"ðŸ“… Date Range: {daily_data['Date'].min()} to {daily_data['Date'].max()}\")\n",
    "print(f\"Total Days: {len(daily_data)}\")\n",
    "print(\"\\nSample Data:\")\n",
    "print(daily_data.head())\n",
    "print(\"\\nData Types:\")\n",
    "print(daily_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5500a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare daily sales data\n",
    "daily_data = traffic_df[['Date', 'Total_Visitors']].copy()\n",
    "daily_data = daily_data.sort_values('Date')\n",
    "\n",
    "# Estimate sales (if product data limited)\n",
    "daily_data['Daily_Sales'] = daily_data['Total_Visitors'] * 5200  # Avg revenue per visitor\n",
    "daily_data['Daily_Orders'] = daily_data['Total_Visitors'] * 0.02  # 2% conversion\n",
    "\n",
    "print(f\"ðŸ“… Date Range: {daily_data['Date'].min()} to {daily_data['Date'].max()}\")\n",
    "print(f\"Total Days: {len(daily_data)}\")\n",
    "print(\"\\nSample Data:\")\n",
    "print(daily_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc29013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Prophet\n",
    "prophet_df = daily_data[['Date', 'Daily_Sales']].copy()\n",
    "prophet_df.columns = ['ds', 'y']\n",
    "prophet_df = prophet_df.dropna()\n",
    "\n",
    "# Ensure ds is datetime\n",
    "prophet_df['ds'] = pd.to_datetime(prophet_df['ds'])\n",
    "\n",
    "print(f\"Prophet data prepared: {len(prophet_df)} rows\")\n",
    "print(f\"Date range: {prophet_df['ds'].min()} to {prophet_df['ds'].max()}\")\n",
    "\n",
    "# Train Prophet model\n",
    "model = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    changepoint_prior_scale=0.05\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Prophet model...\")\n",
    "model.fit(prophet_df)\n",
    "print(\"âœ… Model trained successfully!\")\n",
    "\n",
    "# Make 6-month forecast\n",
    "future = model.make_future_dataframe(periods=180)  # 6 months\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Visualize\n",
    "fig = model.plot(forecast)\n",
    "plt.title('Sales Forecast - Next 6 Months')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales (IDR)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Components\n",
    "fig2 = model.plot_components(forecast)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Forecast completed!\")\n",
    "print(f\"Forecast period: {forecast['ds'].iloc[-180].date()} to {forecast['ds'].iloc[-1].date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc715b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Prophet\n",
    "prophet_df = daily_data[['Date', 'Daily_Sales']].copy()\n",
    "prophet_df.columns = ['ds', 'y']\n",
    "prophet_df = prophet_df.dropna()\n",
    "\n",
    "# Train Prophet model\n",
    "model = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    changepoint_prior_scale=0.05\n",
    ")\n",
    "\n",
    "model.fit(prophet_df)\n",
    "\n",
    "# Make 6-month forecast\n",
    "future = model.make_future_dataframe(periods=180)  # 6 months\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Visualize\n",
    "fig = model.plot(forecast)\n",
    "plt.title('Sales Forecast - Next 6 Months')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales (IDR)')\n",
    "plt.show()\n",
    "\n",
    "# Components\n",
    "fig2 = model.plot_components(forecast)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Forecast completed!\")\n",
    "print(f\"Forecast period: {forecast['ds'].iloc[-180]} to {forecast['ds'].iloc[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2781f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for validation\n",
    "train_size = int(len(prophet_df) * 0.8)\n",
    "train_df = prophet_df[:train_size]\n",
    "test_df = prophet_df[train_size:]\n",
    "\n",
    "print(f\"Training set: {len(train_df)} days\")\n",
    "print(f\"Test set: {len(test_df)} days\")\n",
    "\n",
    "# Train on training set\n",
    "model_eval = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False\n",
    ")\n",
    "model_eval.fit(train_df)\n",
    "\n",
    "# Predict on test set\n",
    "future_test = model_eval.make_future_dataframe(periods=len(test_df))\n",
    "forecast_test = model_eval.predict(future_test)\n",
    "\n",
    "# Calculate metrics\n",
    "y_true = test_df['y'].values\n",
    "y_pred = forecast_test['yhat'].iloc[-len(test_df):].values\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1))) * 100  # Add 1 to avoid division by zero\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL EVALUATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"MAE: IDR {mae:,.0f}\")\n",
    "print(f\"RMSE: IDR {rmse:,.0f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"Accuracy: {(100-mape):.2f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_df['ds'].values, y_true, label='Actual', marker='o', alpha=0.7)\n",
    "plt.plot(test_df['ds'].values, y_pred, label='Predicted', marker='x', alpha=0.7)\n",
    "plt.title('Actual vs Predicted Sales')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales (IDR)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceaaae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for validation\n",
    "train_size = int(len(prophet_df) * 0.8)\n",
    "train_df = prophet_df[:train_size]\n",
    "test_df = prophet_df[train_size:]\n",
    "\n",
    "# Train on training set\n",
    "model_eval = Prophet()\n",
    "model_eval.fit(train_df)\n",
    "\n",
    "# Predict on test set\n",
    "future_test = model_eval.make_future_dataframe(periods=len(test_df))\n",
    "forecast_test = model_eval.predict(future_test)\n",
    "\n",
    "# Calculate metrics\n",
    "y_true = test_df['y'].values\n",
    "y_pred = forecast_test['yhat'].iloc[-len(test_df):].values\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL EVALUATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"MAE: IDR {mae:,.0f}\")\n",
    "print(f\"RMSE: IDR {rmse:,.0f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"Accuracy: {(100-mape):.2f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_df['ds'], y_true, label='Actual', marker='o')\n",
    "plt.plot(test_df['ds'], y_pred, label='Predicted', marker='x')\n",
    "plt.title('Actual vs Predicted Sales')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales (IDR)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for segmentation\n",
    "segment_features = traffic_df[['Total_Visitors', 'New_Visitors', 'Returning_Visitors', 'New_Followers']].copy()\n",
    "\n",
    "# Convert to numeric\n",
    "for col in segment_features.columns:\n",
    "    segment_features[col] = pd.to_numeric(segment_features[col], errors='coerce')\n",
    "\n",
    "segment_features = segment_features.fillna(0)\n",
    "\n",
    "print(f\"Features prepared: {segment_features.shape}\")\n",
    "print(\"\\nFeature statistics:\")\n",
    "print(segment_features.describe())\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(segment_features)\n",
    "\n",
    "# K-Means clustering\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(features_scaled)\n",
    "\n",
    "# Add to dataframe\n",
    "traffic_df['Cluster'] = clusters\n",
    "\n",
    "# Analyze clusters\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CUSTOMER SEGMENTS\")\n",
    "print(\"=\"*60)\n",
    "for i in range(4):\n",
    "    cluster_data = traffic_df[traffic_df['Cluster'] == i]\n",
    "    avg_visitors = pd.to_numeric(cluster_data['Total_Visitors'], errors='coerce').mean()\n",
    "    avg_new = pd.to_numeric(cluster_data['New_Visitors'], errors='coerce').mean()\n",
    "    avg_returning = pd.to_numeric(cluster_data['Returning_Visitors'], errors='coerce').mean()\n",
    "    \n",
    "    print(f\"\\nSegment {i+1}:\")\n",
    "    print(f\"  Size: {len(cluster_data)} days\")\n",
    "    print(f\"  Avg Visitors: {avg_visitors:.0f}\")\n",
    "    print(f\"  Avg New: {avg_new:.0f}\")\n",
    "    print(f\"  Avg Returning: {avg_returning:.0f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize\n",
    "traffic_plot = traffic_df.copy()\n",
    "traffic_plot['Total_Visitors'] = pd.to_numeric(traffic_plot['Total_Visitors'], errors='coerce')\n",
    "traffic_plot['New_Followers'] = pd.to_numeric(traffic_plot['New_Followers'], errors='coerce')\n",
    "\n",
    "fig = px.scatter(traffic_plot, x='Total_Visitors', y='New_Followers', \n",
    "                 color='Cluster', title='Customer Segments',\n",
    "                 labels={'Total_Visitors': 'Total Visitors', 'New_Followers': 'New Followers'},\n",
    "                 color_continuous_scale='viridis')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for segmentation\n",
    "segment_features = traffic_df[['Total_Visitors', 'New_Visitors', 'Returning_Visitors', 'New_Followers']].copy()\n",
    "segment_features = segment_features.fillna(0)\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(segment_features)\n",
    "\n",
    "# K-Means clustering\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(features_scaled)\n",
    "\n",
    "# Add to dataframe\n",
    "traffic_df['Cluster'] = clusters\n",
    "\n",
    "# Analyze clusters\n",
    "print(\"=\"*60)\n",
    "print(\"CUSTOMER SEGMENTS\")\n",
    "print(\"=\"*60)\n",
    "for i in range(4):\n",
    "    cluster_data = traffic_df[traffic_df['Cluster'] == i]\n",
    "    print(f\"\\nSegment {i+1}:\")\n",
    "    print(f\"  Size: {len(cluster_data)} days\")\n",
    "    print(f\"  Avg Visitors: {cluster_data['Total_Visitors'].mean():.0f}\")\n",
    "    print(f\"  Avg New: {cluster_data['New_Visitors'].mean():.0f}\")\n",
    "    print(f\"  Avg Returning: {cluster_data['Returning_Visitors'].mean():.0f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize\n",
    "fig = px.scatter(traffic_df, x='Total_Visitors', y='New_Followers', \n",
    "                 color='Cluster', title='Customer Segments',\n",
    "                 labels={'Total_Visitors': 'Total Visitors', 'New_Followers': 'New Followers'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3132975",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Part 4: Recommendations & Insights\n",
    "\n",
    "### 4.1 Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f09a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary insights\n",
    "insights = {\n",
    "    'Total Revenue': f\"IDR {total_sales/1e6:.1f}M\",\n",
    "    'Conversion Rate': f\"{(total_orders/total_visitors*100):.2f}%\",\n",
    "    'CSAT Score': f\"{avg_csat:.1f}%\",\n",
    "    'Forecast Accuracy': f\"{(100-mape):.2f}%\",\n",
    "    'Top Campaign': 'Flash Sales' if flash_sales > voucher_sales else 'Vouchers',\n",
    "    'Customer Segments': '4 distinct segments identified'\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KEY INSIGHTS & RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "for key, value in insights.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nðŸ“Œ RECOMMENDATIONS:\")\n",
    "print(\"1. Focus on Flash Sales (highest ROI)\")\n",
    "print(\"2. Improve conversion rate (currently 2%)\")\n",
    "print(\"3. Maintain high CSAT score (94%+)\")\n",
    "print(\"4. Target high-value customer segments\")\n",
    "print(\"5. Optimize campaigns during peak traffic periods\")\n",
    "print(\"6. Use forecasting model for inventory planning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c07cc6a",
   "metadata": {},
   "source": [
    "### 4.2 Export Forecast Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export forecast to CSV\n",
    "forecast_export = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(180)\n",
    "forecast_export.columns = ['Date', 'Predicted_Sales', 'Lower_Bound', 'Upper_Bound']\n",
    "forecast_export.to_csv('sales_forecast_6months.csv', index=False)\n",
    "\n",
    "print(\"âœ… Forecast exported to: sales_forecast_6months.csv\")\n",
    "print(f\"Rows: {len(forecast_export)}\")\n",
    "print(\"\\nSample forecast:\")\n",
    "print(forecast_export.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
